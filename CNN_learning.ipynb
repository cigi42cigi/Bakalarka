{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d82df48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librosa version: 0.11.0\n",
      "Numpy version: 1.26.4\n",
      "Matplotlib version: 3.10.3\n",
      "Python version: 1.26.4\n"
     ]
    }
   ],
   "source": [
    "#IMPORTS\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import os\n",
    "\n",
    "print(\"Librosa version:\", librosa.__version__)\n",
    "print(\"Numpy version:\", np.__version__)\n",
    "print(\"Matplotlib version:\", matplotlib.__version__)\n",
    "print(\"Python version:\", np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1da09dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram(path, sr=22050, n_fft=2048, hop_length=512):\n",
    "    y, _ = librosa.load(path, sr=sr)\n",
    "    S = librosa.stft(y, n_fft=n_fft, hop_length=hop_length)\n",
    "    S_db = librosa.amplitude_to_db(np.abs(S), ref=np.max)\n",
    "    return S_db  # 2D matice (frekvence √ó ƒças"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "179a86c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc(path, n_mfcc=13, duration=4.0, sr=22050):\n",
    "    y, _ = librosa.load(path, sr=sr, duration=duration)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    return np.mean(mfcc.T, axis=0)  # pr≈Ømƒõr p≈ôes ƒçasov√© okno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52209a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Downloading ['all', 'index']. Index is being stored in /home/cigi/soundenv/lib/python3.10/site-packages/soundata/datasets/indexes, and the rest of files in /home/cigi/sound_datasets/urbansound8k\n",
      "INFO: [all] downloading UrbanSound8K.tar.gz\n",
      "INFO: /home/cigi/sound_datasets/urbansound8k/UrbanSound8K.tar.gz already exists and will not be downloaded. Rerun with force_overwrite=True to delete this file and force the download.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Kontroluji dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: /home/cigi/sound_datasets/urbansound8k/UrbanSound8K_README.txt already exists. Run with force_overwrite=True to download from scratch\n",
      "INFO: /home/cigi/sound_datasets/urbansound8k/audio already exists. Run with force_overwrite=True to download from scratch\n",
      "INFO: /home/cigi/sound_datasets/urbansound8k/FREESOUNDCREDITS.txt already exists. Run with force_overwrite=True to download from scratch\n",
      "INFO: /home/cigi/sound_datasets/urbansound8k/metadata already exists. Run with force_overwrite=True to download from scratch\n",
      "INFO: [index] downloading urbansound8k_index_1.0.json\n",
      "INFO: /home/cigi/soundenv/lib/python3.10/site-packages/soundata/datasets/indexes/urbansound8k_index_1.0.json already exists and will not be downloaded. Rerun with force_overwrite=True to delete this file and force the download.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 556.42it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8732/8732 [00:16<00:00, 525.42it/s]\n",
      "INFO: Success: the dataset is complete and all files are valid.\n",
      "INFO: --------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç V datab√°zi je 8732 klip≈Ø.\n",
      "‚úÖ Dataset shape: (5503, 1025, 174, 1) (5503,)\n"
     ]
    }
   ],
   "source": [
    "import soundata\n",
    "\n",
    "# Inicializace datasetu\n",
    "dataset = soundata.initialize(\"urbansound8k\")\n",
    "\n",
    "# St√°hne dataset, pokud je≈°tƒõ nen√≠\n",
    "print(\"üì¶ Kontroluji dataset...\")\n",
    "dataset.download()  \n",
    "\n",
    "# Naƒçte metadata\n",
    "dataset.validate()\n",
    "clip_ids = dataset.clip_ids\n",
    "\n",
    "print(f\"üîç V datab√°zi je {len(clip_ids)} klip≈Ø.\")\n",
    "\n",
    "\n",
    "\n",
    "# Kategorie z UrbanSound8K\n",
    "target_labels = ['gun_shot']\n",
    "negative_labels = ['children_playing', 'air_conditioner', 'dog_bark']\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# üîä 1. MFCC z UrbanSound8K\n",
    "for clip_id in dataset.clip_ids:\n",
    "    clip = dataset.clip(clip_id)\n",
    "    if clip.tags:\n",
    "        label = clip.tags.labels[0]\n",
    "        if label in target_labels + negative_labels:\n",
    "            try:\n",
    "                spec = get_spectrogram(clip.audio_path)\n",
    "                X.append(spec)\n",
    "                y.append(1 if label == 'gun_shot' else 0)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Chyba u UrbanSound {clip.audio_path}: {e}\")\n",
    "\n",
    "# üî´ 2. MFCC z vlastn√≠ch Freesound WAV soubor≈Ø\n",
    "FREESOUND_WAV_DIR = \"freesound_gunshots_wav\"\n",
    "for filename in os.listdir(FREESOUND_WAV_DIR):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        try:\n",
    "            path = os.path.join(FREESOUND_WAV_DIR, filename)\n",
    "            spec = get_spectrogram(path)\n",
    "            X.append(spec)\n",
    "            y.append(1)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Chyba u Freesound {filename}: {e}\")\n",
    "\n",
    "# Padding/trimming spectrograms to same shape\n",
    "max_shape = max([x.shape for x in X], key=lambda s: s[1])\n",
    "X_pad = []\n",
    "for spec in X:\n",
    "    pad_width = max_shape[1] - spec.shape[1]\n",
    "    if pad_width > 0:\n",
    "        spec_padded = np.pad(spec, ((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        spec_padded = spec[:, :max_shape[1]]\n",
    "    X_pad.append(spec_padded)\n",
    "\n",
    "X = np.array(X_pad)[..., np.newaxis]  # shape: (samples, freq, time, 1)\n",
    "y = np.array(y)\n",
    "print(\"‚úÖ Dataset shape:\", X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbe4c99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split na tr√©ninkovou a testovac√≠ sadu\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc714406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU dostupn√©: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"GPU dostupn√©:\", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b06eda",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'GlobalAveragePooling2' from 'tensorflow.keras.layers' (/home/cigi/soundenv/lib/python3.10/site-packages/keras/api/_v2/keras/layers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Conv2D, MaxPooling2D, Flatten, Dense, Resizing, Dropout\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GlobalAveragePooling2\n\u001b[1;32m      7\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[1;32m     10\u001b[0m     Resizing(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39minput_shape),\n\u001b[1;32m     11\u001b[0m     Conv2D(\u001b[38;5;241m16\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39minput_shape),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     19\u001b[0m ])\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'GlobalAveragePooling2' from 'tensorflow.keras.layers' (/home/cigi/soundenv/lib/python3.10/site-packages/keras/api/_v2/keras/layers/__init__.py)"
     ]
    }
   ],
   "source": [
    "# Model Neurounky \n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Resizing, Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "model = Sequential([\n",
    "    Resizing(64, 64, input_shape=input_shape),\n",
    "    Conv2D(16, (3, 3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model.save(\"gunshot_cnn_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa6042c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-06 15:08:59.436706: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-06 15:08:59.662940: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-06 15:08:59.662987: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-06 15:08:59.688181: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-06 15:08:59.753863: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-06 15:09:00.587779: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-07-06 15:09:02.067303: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-06 15:09:02.218026: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-06 15:09:02.218058: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-06 15:09:02.223923: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-06 15:09:02.223959: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-06 15:09:02.223971: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-06 15:09:02.338818: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-06 15:09:02.338864: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-06 15:09:02.338869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-07-06 15:09:02.338889: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-06 15:09:02.338902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resizing (Resizing)         (None, 128, 128, 1)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 126, 126, 16)      160       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 63, 63, 16)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 61, 61, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 30, 30, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 28800)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                1843264   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1848129 (7.05 MB)\n",
      "Trainable params: 1848129 (7.05 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Naƒçti ulo≈æen√Ω model\n",
    "model = load_model(\"gunshot_cnn_model.h5\")\n",
    "\n",
    "# Ovƒõ≈ô si, ≈æe je naƒçten√Ω\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82174557",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Tr√©nink modelu\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m, y_train, validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test), epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Tr√©nink modelu\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "181a7ffb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Vyhodnocen√≠ modelu\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m loss, acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(\u001b[43mX_test\u001b[49m, y_test)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Test accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "# Vyhodnocen√≠ modelu\n",
    "\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"‚úÖ Test accuracy: {acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (soundenv)",
   "language": "python",
   "name": "soundenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
